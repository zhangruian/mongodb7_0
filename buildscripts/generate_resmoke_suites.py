#!/usr/bin/env python
"""
Resmoke Test Suite Generator.

Analyze the evergreen history for tests run under the given task and create new evergreen tasks
to attempt to keep the task runtime under a specified amount.
"""

from __future__ import absolute_import

import argparse
import datetime
import itertools
import logging
import os
import sys
from collections import defaultdict
from collections import namedtuple
from operator import itemgetter

import yaml

from shrub.config import Configuration
from shrub.command import CommandDefinition
from shrub.task import TaskDependency
from shrub.variant import DisplayTaskDefinition
from shrub.variant import TaskSpec

from client.github import GithubApi

import client.evergreen as evergreen
import util.read_config as read_config
import util.taskname as taskname
import util.testname as testname
import util.time as timeutil

LOGGER = logging.getLogger(__name__)

MAX_RUNTIME_KEY = "max_runtime"
TEST_SUITE_DIR = os.path.join("buildscripts", "resmokeconfig", "suites")
CONFIG_DIR = "generated_resmoke_config"

HEADER_TEMPLATE = """# DO NOT EDIT THIS FILE. All manual edits will be lost.
# This file was generated by {file} from
# {suite_file}.
"""

CommitRange = namedtuple("CommitRange", ["start", "end"])
ProjectTarget = namedtuple("ProjectTarget", ["owner", "project", "branch"])
Dependencies = namedtuple("Dependencies", ["evergreen", "github"])
ConfigOptions = namedtuple("ConfigOptions", [
    "max_sub_suites",
    "resmoke_args",
    "resmoke_jobs_max",
    "run_multiple_jobs",
    "suite",
    "task",
    "variant",
])


def enable_logging():
    """Enable verbose logging for execution."""

    logging.basicConfig(
        format='[%(asctime)s - %(name)s - %(levelname)s] %(message)s',
        level=logging.DEBUG,
        stream=sys.stdout,
    )


def get_config_options(cmd_line_options, config_file):
    """
    Get the configuration to use for generated tests.

    Command line options override config file options.

    :param cmd_line_options: Command line options specified.
    :param config_file: config file to use.
    :return: ConfigOptions to use.
    """
    config_file_data = read_config.read_config_file(config_file)

    max_sub_suites = read_config.get_config_value("max_sub_suites", cmd_line_options,
                                                  config_file_data)
    resmoke_args = read_config.get_config_value("resmoke_args", cmd_line_options, config_file_data,
                                                default="")
    resmoke_jobs_max = read_config.get_config_value("resmoke_jobs_max", cmd_line_options,
                                                    config_file_data)
    run_multiple_jobs = read_config.get_config_value("run_multiple_jobs", cmd_line_options,
                                                     config_file_data, default="true")
    task = read_config.get_config_value("task", cmd_line_options, config_file_data, required=True)
    suite = read_config.get_config_value("suite", cmd_line_options, config_file_data, default=task)
    variant = read_config.get_config_value("build_variant", cmd_line_options, config_file_data,
                                           required=True)

    return ConfigOptions(max_sub_suites, resmoke_args, resmoke_jobs_max, run_multiple_jobs, suite,
                         task, variant)


def get_start_and_end_commit_since_date(github_api, target, start_date):
    """Get the first and last commits on the given branch from the start date specified."""

    params = {
        "since": "{:%Y-%m-%d}T00:00:00Z".format(start_date),
        "sha": target.branch,
    }

    commits = github_api.get_commits(target.owner, target.project, params)

    return CommitRange(commits[-1]["sha"], commits[0]["sha"])


def get_history_by_revision(evergreen_api, task, commit_range, evg_project, variants):
    """Call to the evergreen API to get the test history for the specified task."""

    params = {
        "sort": "latest",
        "tasks": task,
        "afterRevision": commit_range.start,
        "beforeRevision": commit_range.end,
        "testStatuses": "pass",
        "taskStatuses": "success",
    }

    if variants:
        params["variants"] = variants

    LOGGER.debug("evergreen get_history, params=%s", params)

    return evergreen_api.get_history(evg_project, params)


def get_test_history(evergreen_api, target, task, commit_range, variants):
    """Get test history from evergreen, repeating if the data was paginated."""

    evg_project = evergreen.generate_evergreen_project_name(target.owner, target.project,
                                                            target.branch)
    test_history = []
    iteration = 0
    while commit_range.start != commit_range.end:
        history = get_history_by_revision(evergreen_api, task, commit_range, evg_project, variants)
        LOGGER.debug("test_history[%d]=%d, commit_range=%s", iteration, len(history), commit_range)

        if not history:
            break

        test_history += history

        # The first test will have the latest revision for this result set because
        # get_history_by_revision() sorts by "latest".
        commit_range = CommitRange(history[0]["revision"], commit_range.end)

        LOGGER.debug("commit_range=%s", commit_range)
        iteration += 1

    return test_history


def split_hook_runs_out(executions):
    """Split the list of executions into a list of test executions and list of hook executions."""

    def is_execution_a_hook(execution):
        """Is the given execution object for a test hook."""

        test_file = testname.normalize_test_file(execution["test_file"])
        return testname.is_resmoke_hook(test_file)

    test_executions = [e for e in executions if not is_execution_a_hook(e)]
    hook_executions = [e for e in executions if is_execution_a_hook(e)]

    return test_executions, hook_executions


def group_by_attribute(list_to_group, attrib):
    """Sort and group a given list by the specified attribute."""

    return itertools.groupby(sorted(list_to_group, key=itemgetter(attrib)), key=itemgetter(attrib))


def organize_hooks(executions):
    """Organize the duration of hooks into a dictionary."""
    hooks = defaultdict(lambda: defaultdict(lambda: defaultdict(int)))

    for rev, rev_group in group_by_attribute(executions, "revision"):
        for variant, var_group in group_by_attribute(rev_group, "variant"):
            for hook in var_group:
                name = testname.split_test_hook_name(hook["test_file"])[0]
                hooks[rev][variant][name] += hook["duration"]

    return hooks


def execution_runtime(test_file, execution, hooks):
    """Calculate the runtime for the given execution."""

    rev = execution["revision"]
    variant = execution["variant"]
    runtime = timeutil.ns2sec(execution["duration"])
    possible_hook_name = testname.get_short_name_from_test_file(test_file)
    if rev in hooks and variant in hooks[rev] and possible_hook_name in hooks[rev][variant]:
        runtime += timeutil.ns2sec(hooks[rev][variant][possible_hook_name])

    return runtime


def organize_executions_by_test(executions):
    """Organize the list of test executions into a dictionary execution data about each test."""

    (test_executions, hook_executions) = split_hook_runs_out(executions)

    hooks = organize_hooks(hook_executions)

    def group_by_test_name(test_list):
        """Group the given test list by name."""

        def key_function(execution):
            """Get the normalized test_file for the given execution."""

            return testname.normalize_test_file(execution["test_file"])

        return itertools.groupby(sorted(test_list, key=key_function), key=key_function)

    tests = defaultdict(lambda: defaultdict(int))

    for test_file, tf_group in group_by_test_name(test_executions):
        # Only include test files that exist (a test file could have recently been deleted)
        if os.path.isfile(test_file):
            for variant, variant_group in group_by_attribute(tf_group, "variant"):
                runs = [execution_runtime(test_file, e, hooks) for e in variant_group]
                ave_execution_time = average_of_array(runs)
                tests[test_file][variant] = ave_execution_time

                if ave_execution_time > tests[test_file][MAX_RUNTIME_KEY]:
                    tests[test_file][MAX_RUNTIME_KEY] = ave_execution_time

    return tests


def average_of_array(array):
    """Calculate the average value in the given array."""
    total = sum(array)
    count = len(array)

    return total / count


def sort_list_of_test_by_max_runtime(tests):
    """Return a list of tests sorted by descending average runtime."""
    return sorted(tests.keys(), key=lambda test: tests[test][MAX_RUNTIME_KEY], reverse=True)


def divide_remaining_tests_among_suites(remaining_tests, tests, suites):
    """Divide the list of tests given among the suites given."""
    suite_idx = 0
    for test_name in remaining_tests:
        test = tests[test_name]
        current_suite = suites[suite_idx]
        current_suite.add_test(test_name, test)
        suite_idx += 1
        if suite_idx >= len(suites):
            suite_idx = 0


def divide_tests_into_suites_by_maxtime(tests, sorted_tests, max_time_seconds, max_suites=None):
    """
    Divide the given tests into suites.

    Each suite should be able to execute in less than the max time specified.
    """
    suites = []
    current_suite = Suite()
    last_test_processed = len(sorted_tests)
    LOGGER.debug("Determines suites for runtime: %ds", max_time_seconds)
    for idx, test_name in enumerate(sorted_tests):
        test = tests[test_name]
        if current_suite.get_runtime() + test[MAX_RUNTIME_KEY] > max_time_seconds:
            LOGGER.debug("Runtime(%d) + new test(%d) > max(%d)", current_suite.get_runtime(),
                         test[MAX_RUNTIME_KEY], max_time_seconds)
            if current_suite.get_test_count() > 0:
                suites.append(current_suite)
                current_suite = Suite()
                if max_suites and len(suites) >= max_suites:
                    last_test_processed = idx
                    break

        current_suite.add_test(test_name, test)

    if current_suite.get_test_count() > 0:
        suites.append(current_suite)

    if max_suites and last_test_processed < len(sorted_tests):
        # We must have hit the max suite limit, just randomly add the remaining tests to suites.
        divide_remaining_tests_among_suites(sorted_tests[last_test_processed:], tests, suites)

    return suites


def generate_subsuite_file(source_suite_name, target_suite_name, roots=None, excludes=None):
    """
    Read and evaluate the yaml suite file.

    Override selector.roots and selector.excludes with the provided values. Write the results to
    target_suite_name.
    """
    source_file = os.path.join(TEST_SUITE_DIR, source_suite_name + ".yml")
    with open(source_file, "r") as fstream:
        suite_config = yaml.load(fstream)

    with open(os.path.join(CONFIG_DIR, target_suite_name + ".yml"), 'w') as out:
        out.write(HEADER_TEMPLATE.format(file=__file__, suite_file=source_file))
        if roots:
            suite_config['selector']['roots'] = roots
        if excludes:
            suite_config['selector']['exclude_files'] = excludes
        out.write(yaml.dump(suite_config, default_flow_style=False, Dumper=yaml.SafeDumper))


def render_suite(suites, suite_name):
    """Render the given suites into yml files that can be used by resmoke.py."""
    for idx, suite in enumerate(suites):
        suite.name = taskname.name_generated_task(suite_name, idx, len(suites))
        generate_subsuite_file(suite_name, suite.name, roots=suite.tests)


def render_misc_suite(test_list, suite_name):
    """Render a misc suite to run any tests that might be added to the directory."""
    subsuite_name = "{0}_{1}".format(suite_name, "misc")
    generate_subsuite_file(suite_name, subsuite_name, excludes=test_list)


def prepare_directory_for_suite(directory):
    """Ensure that dir exists."""
    if not os.path.exists(directory):
        os.makedirs(directory)


def generate_evg_config(suites, options):
    """Generate evergreen configuration for the given suites."""
    evg_config = Configuration()

    task_names = []
    task_specs = []

    def generate_task(sub_suite_name, sub_task_name):
        """Generate evergreen config for a resmoke task."""
        task_names.append(sub_task_name)
        task_specs.append(TaskSpec(sub_task_name))
        task = evg_config.task(sub_task_name)

        target_suite_file = os.path.join(CONFIG_DIR, sub_suite_name)

        run_tests_vars = {
            "resmoke_args": "--suites={0} {1}".format(target_suite_file, options.resmoke_args),
            "run_multiple_jobs": options.run_multiple_jobs,
        }

        if options.resmoke_jobs_max:
            run_tests_vars["resmoke_jobs_max"] = options.resmoke_jobs_max

        commands = [
            CommandDefinition().function("do setup"),
            CommandDefinition().function("run tests").vars(run_tests_vars)
        ]
        task.dependency(TaskDependency("compile")).commands(commands)

    for idx, suite in enumerate(suites):
        sub_task_name = taskname.name_generated_task(options.task, idx, len(suites),
                                                     options.variant)
        generate_task(suite.name, sub_task_name)

    # Add the misc suite
    misc_suite_name = "{0}_misc".format(options.suite)
    generate_task(misc_suite_name, "{0}_misc_{1}".format(options.task, options.variant))

    dt = DisplayTaskDefinition(options.task).execution_tasks(task_names) \
        .execution_task("{0}_gen".format(options.task))
    evg_config.variant(options.variant).tasks(task_specs).display_task(dt)

    return evg_config


class Suite(object):
    """A suite of tests that can be run by evergreen."""

    def __init__(self):
        """Initialize the object."""
        self.tests = []
        self.total_runtime = 0
        self.variant_runtime = defaultdict(int)
        self._name = None

    def add_test(self, test_name, test_data):
        """Add the given test to this suite."""

        self.tests.append(test_name)
        for variant in test_data:
            if variant == MAX_RUNTIME_KEY:
                self.total_runtime += test_data[variant]
            else:
                self.variant_runtime[variant] += test_data[variant]

    def get_runtime(self):
        """Get the current average runtime of all the tests currently in this suite."""

        return self.total_runtime

    def get_test_count(self):
        """Get the number of tests currently in this suite."""

        return len(self.tests)


class Main(object):
    """Orchestrate the execution of generate_resmoke_suites."""

    def __init__(self, deps):
        """Initialize the object."""
        self.deps = deps
        self.options = {}
        self.config_options = {}
        self.commit_range = None
        self.test_list = []

    def parse_commandline(self):
        """Parse the command line options and return the parsed data."""
        parser = argparse.ArgumentParser(description=self.main.__doc__)

        parser.add_argument("--expansion-file", dest="expansion_file", type=str,
                            help="Location of expansions file generated by evergreen.")
        parser.add_argument("--analysis-duration", dest="duration_days", default=14,
                            help="Number of days to analyze.", type=int)
        parser.add_argument("--branch", dest="branch", default="master",
                            help="Branch of project to analyze.")
        parser.add_argument("--end-commit", dest="end_commit", help="End analysis at this commit.")
        parser.add_argument("--execution-time", dest="execution_time_minutes", default=60, type=int,
                            help="Target execution time (in minutes).")
        parser.add_argument("--github-owner", dest="owner", default="mongodb",
                            help="Owner of github project to analyse.")
        parser.add_argument("--github-project", dest="project", default="mongo",
                            help="Github project to analyse.")
        parser.add_argument("--start-commit", dest="start_commit",
                            help="Start analysis at this commit.")
        parser.add_argument("--variants", dest="variants", metavar="<variant1,variant2,...>",
                            default=None,
                            help="Comma-separated list of Evergreeen build variants to analyze.")
        parser.add_argument("--max-sub-suites", dest="max_sub_suites", type=int,
                            help="Max number of suites to divide into.")
        parser.add_argument("--resmoke-args", dest="resmoke_args",
                            help="Arguments to pass to resmoke calls.")
        parser.add_argument("--resmoke-jobs_max", dest="resmoke_jobs_max",
                            help="Number of resmoke jobs to invoke.")
        parser.add_argument("--suite", dest="suite",
                            help="Name of suite being split(defaults to task_name)")
        parser.add_argument("--run-multiple-jobs", dest="run_multiple_jobs",
                            help="Should resmoke run multiple jobs")
        parser.add_argument("--task_name", dest="task", help="Name of task to split.")
        parser.add_argument("--variant", dest="build_variant",
                            help="Build variant being run against.")
        parser.add_argument("--verbose", dest="verbose", action="store_true", default=False,
                            help="Enable verbose logging.")

        options = parser.parse_args()

        if options.start_commit or options.end_commit:
            if not options.start_commit or not options.end_commit:
                parser.error("--start-commit and --end-commit must both be specified")

        self.config_options = get_config_options(options, options.expansion_file)

        return options

    def get_data(self, target, start_date, task, variants):
        """Collect history test data from github and evergreen."""
        if not self.commit_range:
            self.commit_range = get_start_and_end_commit_since_date(self.deps.github, target,
                                                                    start_date)
        return get_test_history(self.deps.evergreen, target, task, self.commit_range, variants)

    def calculate_suites(self, data, execution_time_secs):
        """Divide test into suites that can be run in less than the specified execution time."""
        tests = organize_executions_by_test(data)
        self.test_list = sort_list_of_test_by_max_runtime(tests)
        return divide_tests_into_suites_by_maxtime(tests, self.test_list, execution_time_secs,
                                                   self.options.max_sub_suites)

    def write_evergreen_configuration(self, suites, task):
        """Generate the evergreen configuration for the new suite and write it to disk."""
        evg_config = generate_evg_config(suites, self.config_options)

        with open(os.path.join(CONFIG_DIR, task + ".json"), "w") as file_handle:
            file_handle.write(evg_config.to_json())

    def main(self):
        """Generate resmoke suites that run within a specified target execution time."""

        options = self.parse_commandline()
        self.options = options

        if options.verbose:
            enable_logging()

        if options.start_commit or options.end_commit:
            self.commit_range = CommitRange(options.start_commit, options.end_commit)

        LOGGER.debug("Starting execution for options %s", options)
        today = datetime.datetime.utcnow().replace(microsecond=0)
        start_date = today - datetime.timedelta(days=options.duration_days)
        target = ProjectTarget(options.owner, options.project, options.branch)

        prepare_directory_for_suite(CONFIG_DIR)

        data = self.get_data(target, start_date, self.config_options.task, options.variants)
        suites = self.calculate_suites(data, options.execution_time_minutes * 60)

        LOGGER.debug("Creating %d suites for %s", len(suites), self.config_options.task)

        render_suite(suites, self.config_options.suite)
        render_misc_suite(self.test_list, self.config_options.suite)

        self.write_evergreen_configuration(suites, self.config_options.task)


if __name__ == "__main__":
    Main(Dependencies(evergreen.get_evergreen_api(), GithubApi())).main()
